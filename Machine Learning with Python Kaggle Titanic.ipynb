{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Python to solve the Kaggle Titanic case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting and Cleaning both the test and train datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first steps we will go trough the essential steps of getting and cleaning the data that we will need to take before beginning to build predictive models to explore how to tackle Kaggle Titanic competition using Python and Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we run the necessary Jupyter magic so that plots are displayed inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import the Pandas library and load and read both the train and test datasets to create two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\"\n",
    "train = pd.read_csv(train_url)\n",
    "\n",
    "test_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv\"\n",
    "test = pd.read_csv(test_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we print the `head` of the train and test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start with the actual analysis of the dataframes, it's important that we understand the structure of your data. Both the test and train datasets are DataFrame objects, the way pandas represent datasets. We can easily explore a DataFrame using the .describe() method. The .describe() method summarizes the columns/features of the DataFrame, including the count of observations, mean, max and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
       "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
       "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
       "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
       "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
       "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
       "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
       "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful trick is to look at the dimensions of the DataFrame. This is done by requesting the .shape attribute of our DataFrame objects with the help of the numpy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.shape(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.shape(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many people in your training set survived the disaster with the Titanic? To see this, you can use the value_counts() method in combination with standard bracket notation to select a single column of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that 549 individuals died (62%) and 342 survived (38%). A simple way to predict heuristically could be: \"majority wins\". This would mean that we will predict every unseen observation to not survive. To dive in a little deeper we can perform similar counts and percentage calculations on subsets of the Survived column. For example, maybe gender could play a role as well? We can explore this using the .value_counts() method for a two-way comparison on the number of males and females that survived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passengers that survived vs passengers that passed away in total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"Survived\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passengers that survived vs passengers that passed away as proportions, to get proportions, we pass in the argument: normalize = True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"Survived\"].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore if maybe gender played a role we use the .value_counts() method for a two-way comparison on the number of males and females that survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    468\n",
      "1    109\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we will do the same exploration, only this time by looking at the proportions instead of the totals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.811092\n",
      "1    0.188908\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.742038\n",
      "0    0.257962\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another variable that could influence survival is age; since it's probable that children were saved first. We can test this by creating a new column with a categorical variable Child. The new variabele Child will take the value 1 in cases where age is less than 18, and a value of 0 in cases where age is greater than or equal to 18. To add this new variable we need to do two things (i) create a new column, and (ii) provide the values for each observation (i.e., row) based on the age of the passenger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we create a new column called \"Child\" and we define that missing values will count 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"Child\"] = float('NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we assign 1 to passengers under 18, and we assing 0 to those missing or at the age of 18 and older."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7      True\n",
       "9      True\n",
       "10     True\n",
       "14     True\n",
       "16     True\n",
       "22     True\n",
       "24     True\n",
       "39     True\n",
       "43     True\n",
       "50     True\n",
       "58     True\n",
       "59     True\n",
       "63     True\n",
       "68     True\n",
       "71     True\n",
       "78     True\n",
       "84     True\n",
       "86     True\n",
       "111    True\n",
       "114    True\n",
       "119    True\n",
       "125    True\n",
       "138    True\n",
       "147    True\n",
       "156    True\n",
       "163    True\n",
       "164    True\n",
       "165    True\n",
       "171    True\n",
       "172    True\n",
       "       ... \n",
       "691    True\n",
       "720    True\n",
       "721    True\n",
       "731    True\n",
       "746    True\n",
       "750    True\n",
       "751    True\n",
       "755    True\n",
       "764    True\n",
       "777    True\n",
       "780    True\n",
       "781    True\n",
       "787    True\n",
       "788    True\n",
       "791    True\n",
       "802    True\n",
       "803    True\n",
       "813    True\n",
       "819    True\n",
       "824    True\n",
       "827    True\n",
       "830    True\n",
       "831    True\n",
       "841    True\n",
       "844    True\n",
       "850    True\n",
       "852    True\n",
       "853    True\n",
       "869    True\n",
       "875    True\n",
       "Name: Child, dtype: bool"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Child\"][train[\"Age\"] < 18] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "6      True\n",
       "8      True\n",
       "11     True\n",
       "12     True\n",
       "13     True\n",
       "15     True\n",
       "18     True\n",
       "20     True\n",
       "21     True\n",
       "23     True\n",
       "25     True\n",
       "27     True\n",
       "30     True\n",
       "33     True\n",
       "34     True\n",
       "35     True\n",
       "37     True\n",
       "38     True\n",
       "40     True\n",
       "41     True\n",
       "44     True\n",
       "49     True\n",
       "51     True\n",
       "52     True\n",
       "53     True\n",
       "       ... \n",
       "854    True\n",
       "855    True\n",
       "856    True\n",
       "857    True\n",
       "858    True\n",
       "860    True\n",
       "861    True\n",
       "862    True\n",
       "864    True\n",
       "865    True\n",
       "866    True\n",
       "867    True\n",
       "870    True\n",
       "871    True\n",
       "872    True\n",
       "873    True\n",
       "874    True\n",
       "876    True\n",
       "877    True\n",
       "879    True\n",
       "880    True\n",
       "881    True\n",
       "882    True\n",
       "883    True\n",
       "884    True\n",
       "885    True\n",
       "886    True\n",
       "887    True\n",
       "889    True\n",
       "890    True\n",
       "Name: Child, dtype: bool"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Child\"][train[\"Age\"] >= 18] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now we have to print the new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "5      NaN\n",
      "6      0.0\n",
      "7      1.0\n",
      "8      0.0\n",
      "9      1.0\n",
      "10     1.0\n",
      "11     0.0\n",
      "12     0.0\n",
      "13     0.0\n",
      "14     1.0\n",
      "15     0.0\n",
      "16     1.0\n",
      "17     NaN\n",
      "18     0.0\n",
      "19     NaN\n",
      "20     0.0\n",
      "21     0.0\n",
      "22     1.0\n",
      "23     0.0\n",
      "24     1.0\n",
      "25     0.0\n",
      "26     NaN\n",
      "27     0.0\n",
      "28     NaN\n",
      "29     NaN\n",
      "      ... \n",
      "861    0.0\n",
      "862    0.0\n",
      "863    NaN\n",
      "864    0.0\n",
      "865    0.0\n",
      "866    0.0\n",
      "867    0.0\n",
      "868    NaN\n",
      "869    1.0\n",
      "870    0.0\n",
      "871    0.0\n",
      "872    0.0\n",
      "873    0.0\n",
      "874    0.0\n",
      "875    1.0\n",
      "876    0.0\n",
      "877    0.0\n",
      "878    NaN\n",
      "879    0.0\n",
      "880    0.0\n",
      "881    0.0\n",
      "882    0.0\n",
      "883    0.0\n",
      "884    0.0\n",
      "885    0.0\n",
      "886    0.0\n",
      "887    0.0\n",
      "888    NaN\n",
      "889    0.0\n",
      "890    0.0\n",
      "Name: Child, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"Child\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the normalized Survival Rates for passengers above 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.539823\n",
      "0    0.460177\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"Survived\"][train[\"Child\"] == 1].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the normalized Survival Rates for passengers above 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.618968\n",
      "1    0.381032\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"Survived\"][train[\"Child\"] == 0].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier we discovered that in your training set, females had over a 50% chance of surviving and males had less than a 50% chance of surviving. Hence, we could use this information for our first prediction: all females in the test set survive and all males in the test set die. We will use your test set for validating our predictions. We might have seen that contrary to the training set, the test set has no Survived column. You add such a column using your predicted values. Next, when uploading your results, Kaggle will use this variable (= your predictions) to score your performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we create a copy of the test dataframe called: test_one, we initialize a survived column to 0 in the test_one dataframe and then we set Survived to 1 if Sex equals \"female\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      True\n",
       "4      True\n",
       "6      True\n",
       "8      True\n",
       "12     True\n",
       "14     True\n",
       "15     True\n",
       "18     True\n",
       "19     True\n",
       "22     True\n",
       "24     True\n",
       "26     True\n",
       "32     True\n",
       "33     True\n",
       "36     True\n",
       "37     True\n",
       "43     True\n",
       "44     True\n",
       "48     True\n",
       "49     True\n",
       "52     True\n",
       "53     True\n",
       "59     True\n",
       "63     True\n",
       "65     True\n",
       "66     True\n",
       "69     True\n",
       "70     True\n",
       "72     True\n",
       "74     True\n",
       "       ... \n",
       "347    True\n",
       "349    True\n",
       "350    True\n",
       "354    True\n",
       "356    True\n",
       "359    True\n",
       "361    True\n",
       "362    True\n",
       "364    True\n",
       "365    True\n",
       "367    True\n",
       "368    True\n",
       "371    True\n",
       "374    True\n",
       "375    True\n",
       "376    True\n",
       "382    True\n",
       "383    True\n",
       "385    True\n",
       "391    True\n",
       "395    True\n",
       "397    True\n",
       "400    True\n",
       "402    True\n",
       "408    True\n",
       "409    True\n",
       "410    True\n",
       "411    True\n",
       "412    True\n",
       "414    True\n",
       "Name: Survived, dtype: bool"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_one = test\n",
    "test_one[\"Survived\"] == 0\n",
    "test_one[\"Survived\"][test_one[\"Sex\"] == \"female\"] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we print the result of our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      1\n",
      "5      0\n",
      "6      1\n",
      "7      0\n",
      "8      1\n",
      "9      0\n",
      "10     0\n",
      "11     0\n",
      "12     1\n",
      "13     0\n",
      "14     1\n",
      "15     1\n",
      "16     0\n",
      "17     0\n",
      "18     1\n",
      "19     1\n",
      "20     0\n",
      "21     0\n",
      "22     1\n",
      "23     0\n",
      "24     1\n",
      "25     0\n",
      "26     1\n",
      "27     0\n",
      "28     0\n",
      "29     0\n",
      "      ..\n",
      "388    0\n",
      "389    0\n",
      "390    0\n",
      "391    1\n",
      "392    0\n",
      "393    0\n",
      "394    0\n",
      "395    1\n",
      "396    0\n",
      "397    1\n",
      "398    0\n",
      "399    0\n",
      "400    1\n",
      "401    0\n",
      "402    1\n",
      "403    0\n",
      "404    0\n",
      "405    0\n",
      "406    0\n",
      "407    0\n",
      "408    1\n",
      "409    1\n",
      "410    1\n",
      "411    1\n",
      "412    1\n",
      "413    0\n",
      "414    1\n",
      "415    0\n",
      "416    0\n",
      "417    0\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_one.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees to automate slicing and deciding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, we did all the slicing and dicing ourself to find subsets that have a higher chance of surviving. A decision tree automates this process for us and outputs a classification model or classifier. Conceptually, the decision tree algorithm starts with all the data at the root node and scans all the variables for the best one to split on. Once a variable is chosen, it does the split and goes down one level (or one node) and repeat. The final nodes at the bottom of the decision tree are known as terminal nodes, and the majority vote of the observations in that node determine how to predict for new observations that end up in that terminal node.\n",
    "\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can begin constructing our trees we need to get our hands dirty and clean the data so that we can use all the features available to us. In the first chapter, we saw that the Age variable had some missing value. Missingness is a whole subject with and in itself, but we will use a simple imputation technique where we substitute each missing value with the median of the all present values. Another problem is that the Sex and Embarked variables are categorical but in a non-numeric format. Thus, we will need to assign each class a unique integer so that Python can handle the information. Embarked also has some missing values which we should impute witht the most common class of embarkation, which is \"S\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we convert the male and female groups to integer form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Sex, dtype: bool)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Sex\"][train[\"Sex\"] == \"male\"] == 0\n",
    "train[\"Sex\"][train[\"Sex\"] == \"female\"] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we impute the Embarked variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we convert the Embarked classes to integer form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Embarked, dtype: bool)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Embarked\"][train[\"Embarked\"] == \"S\"] == 0\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"C\"] == 1\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"Q\"] == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the Sex and Embarked columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "5      0\n",
      "6      0\n",
      "7      0\n",
      "8      1\n",
      "9      1\n",
      "10     1\n",
      "11     1\n",
      "12     0\n",
      "13     0\n",
      "14     1\n",
      "15     1\n",
      "16     0\n",
      "17     0\n",
      "18     1\n",
      "19     1\n",
      "20     0\n",
      "21     0\n",
      "22     1\n",
      "23     0\n",
      "24     1\n",
      "25     1\n",
      "26     0\n",
      "27     0\n",
      "28     1\n",
      "29     0\n",
      "      ..\n",
      "861    0\n",
      "862    1\n",
      "863    1\n",
      "864    0\n",
      "865    1\n",
      "866    1\n",
      "867    0\n",
      "868    0\n",
      "869    0\n",
      "870    0\n",
      "871    1\n",
      "872    0\n",
      "873    0\n",
      "874    1\n",
      "875    1\n",
      "876    0\n",
      "877    0\n",
      "878    0\n",
      "879    1\n",
      "880    1\n",
      "881    0\n",
      "882    1\n",
      "883    0\n",
      "884    0\n",
      "885    1\n",
      "886    0\n",
      "887    1\n",
      "888    1\n",
      "889    0\n",
      "890    0\n",
      "Name: Sex, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train[\"Sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "5      2\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "9      1\n",
      "10     0\n",
      "11     0\n",
      "12     0\n",
      "13     0\n",
      "14     0\n",
      "15     0\n",
      "16     2\n",
      "17     0\n",
      "18     0\n",
      "19     1\n",
      "20     0\n",
      "21     0\n",
      "22     2\n",
      "23     0\n",
      "24     0\n",
      "25     0\n",
      "26     1\n",
      "27     0\n",
      "28     2\n",
      "29     0\n",
      "      ..\n",
      "861    0\n",
      "862    0\n",
      "863    0\n",
      "864    0\n",
      "865    0\n",
      "866    1\n",
      "867    0\n",
      "868    0\n",
      "869    0\n",
      "870    0\n",
      "871    0\n",
      "872    0\n",
      "873    0\n",
      "874    1\n",
      "875    1\n",
      "876    0\n",
      "877    0\n",
      "878    0\n",
      "879    1\n",
      "880    0\n",
      "881    0\n",
      "882    0\n",
      "883    0\n",
      "884    0\n",
      "885    2\n",
      "886    0\n",
      "887    0\n",
      "888    0\n",
      "889    1\n",
      "890    2\n",
      "Name: Embarked, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the scikit-learn and numpy libraries to build our first decision tree. scikit-learn can be used to create tree objects from the DecisionTreeClassifier class. The methods that we will use take numpy arrays as inputs and therefore we will need to create those from the DataFrame that we already have. We will need the following to build a decision tree: a target: A one-dimensional numpy array containing the target/response from the train data. (Survival in your case) and features: A multidimensional numpy array containing the features/predictors from the train data. (ex. Sex, Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the target and features numpy arrays, called: target and features_one. Then we fit our first decision tree, called: my_tree_one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "5              6         0       3   \n",
      "6              7         0       1   \n",
      "7              8         0       3   \n",
      "8              9         1       3   \n",
      "9             10         1       2   \n",
      "10            11         1       3   \n",
      "11            12         1       1   \n",
      "12            13         0       3   \n",
      "13            14         0       3   \n",
      "14            15         0       3   \n",
      "15            16         1       2   \n",
      "16            17         0       3   \n",
      "17            18         1       2   \n",
      "18            19         0       3   \n",
      "19            20         1       3   \n",
      "20            21         0       2   \n",
      "21            22         1       2   \n",
      "22            23         1       3   \n",
      "23            24         1       1   \n",
      "24            25         0       3   \n",
      "25            26         1       3   \n",
      "26            27         0       3   \n",
      "27            28         0       1   \n",
      "28            29         1       3   \n",
      "29            30         0       3   \n",
      "..           ...       ...     ...   \n",
      "861          862         0       2   \n",
      "862          863         1       1   \n",
      "863          864         0       3   \n",
      "864          865         0       2   \n",
      "865          866         1       2   \n",
      "866          867         1       2   \n",
      "867          868         0       1   \n",
      "868          869         0       3   \n",
      "869          870         1       3   \n",
      "870          871         0       3   \n",
      "871          872         1       1   \n",
      "872          873         0       1   \n",
      "873          874         0       3   \n",
      "874          875         1       2   \n",
      "875          876         1       3   \n",
      "876          877         0       3   \n",
      "877          878         0       3   \n",
      "878          879         0       3   \n",
      "879          880         1       1   \n",
      "880          881         1       2   \n",
      "881          882         0       3   \n",
      "882          883         0       3   \n",
      "883          884         0       2   \n",
      "884          885         0       3   \n",
      "885          886         0       3   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris   0  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina   1  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.0      1   \n",
      "4                             Allen, Mr. William Henry   0  35.0      0   \n",
      "5                                     Moran, Mr. James   0   NaN      0   \n",
      "6                              McCarthy, Mr. Timothy J   0  54.0      0   \n",
      "7                       Palsson, Master. Gosta Leonard   0   2.0      3   \n",
      "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   1  27.0      0   \n",
      "9                  Nasser, Mrs. Nicholas (Adele Achem)   1  14.0      1   \n",
      "10                     Sandstrom, Miss. Marguerite Rut   1   4.0      1   \n",
      "11                            Bonnell, Miss. Elizabeth   1  58.0      0   \n",
      "12                      Saundercock, Mr. William Henry   0  20.0      0   \n",
      "13                         Andersson, Mr. Anders Johan   0  39.0      1   \n",
      "14                Vestrom, Miss. Hulda Amanda Adolfina   1  14.0      0   \n",
      "15                    Hewlett, Mrs. (Mary D Kingcome)    1  55.0      0   \n",
      "16                                Rice, Master. Eugene   0   2.0      4   \n",
      "17                        Williams, Mr. Charles Eugene   0   NaN      0   \n",
      "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...   1  31.0      1   \n",
      "19                             Masselmani, Mrs. Fatima   1   NaN      0   \n",
      "20                                Fynney, Mr. Joseph J   0  35.0      0   \n",
      "21                               Beesley, Mr. Lawrence   0  34.0      0   \n",
      "22                         McGowan, Miss. Anna \"Annie\"   1  15.0      0   \n",
      "23                        Sloper, Mr. William Thompson   0  28.0      0   \n",
      "24                       Palsson, Miss. Torborg Danira   1   8.0      3   \n",
      "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...   1  38.0      1   \n",
      "26                             Emir, Mr. Farred Chehab   0   NaN      0   \n",
      "27                      Fortune, Mr. Charles Alexander   0  19.0      3   \n",
      "28                       O'Dwyer, Miss. Ellen \"Nellie\"   1   NaN      0   \n",
      "29                                 Todoroff, Mr. Lalio   0   NaN      0   \n",
      "..                                                 ...  ..   ...    ...   \n",
      "861                        Giles, Mr. Frederick Edward   0  21.0      1   \n",
      "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...   1  48.0      0   \n",
      "863                  Sage, Miss. Dorothy Edith \"Dolly\"   1   NaN      8   \n",
      "864                             Gill, Mr. John William   0  24.0      0   \n",
      "865                           Bystrom, Mrs. (Karolina)   1  42.0      0   \n",
      "866                       Duran y More, Miss. Asuncion   1  27.0      1   \n",
      "867               Roebling, Mr. Washington Augustus II   0  31.0      0   \n",
      "868                        van Melkebeke, Mr. Philemon   0   NaN      0   \n",
      "869                    Johnson, Master. Harold Theodor   0   4.0      1   \n",
      "870                                  Balkic, Mr. Cerin   0  26.0      0   \n",
      "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)   1  47.0      1   \n",
      "872                           Carlsson, Mr. Frans Olof   0  33.0      0   \n",
      "873                        Vander Cruyssen, Mr. Victor   0  47.0      0   \n",
      "874              Abelson, Mrs. Samuel (Hannah Wizosky)   1  28.0      1   \n",
      "875                   Najib, Miss. Adele Kiamie \"Jane\"   1  15.0      0   \n",
      "876                      Gustafsson, Mr. Alfred Ossian   0  20.0      0   \n",
      "877                               Petroff, Mr. Nedelio   0  19.0      0   \n",
      "878                                 Laleff, Mr. Kristo   0   NaN      0   \n",
      "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)   1  56.0      0   \n",
      "880       Shelley, Mrs. William (Imanita Parrish Hall)   1  25.0      0   \n",
      "881                                 Markun, Mr. Johann   0  33.0      0   \n",
      "882                       Dahlberg, Miss. Gerda Ulrika   1  22.0      0   \n",
      "883                      Banfield, Mr. Frederick James   0  28.0      0   \n",
      "884                             Sutehall, Mr. Henry Jr   0  25.0      0   \n",
      "885               Rice, Mrs. William (Margaret Norton)   1  39.0      0   \n",
      "886                              Montvila, Rev. Juozas   0  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith   1  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"   1   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell   0  26.0      0   \n",
      "890                                Dooley, Mr. Patrick   0  32.0      0   \n",
      "\n",
      "     Parch            Ticket      Fare        Cabin Embarked  Child  \n",
      "0        0         A/5 21171    7.2500          NaN        0    0.0  \n",
      "1        0          PC 17599   71.2833          C85        1    0.0  \n",
      "2        0  STON/O2. 3101282    7.9250          NaN        0    0.0  \n",
      "3        0            113803   53.1000         C123        0    0.0  \n",
      "4        0            373450    8.0500          NaN        0    0.0  \n",
      "5        0            330877    8.4583          NaN        2    NaN  \n",
      "6        0             17463   51.8625          E46        0    0.0  \n",
      "7        1            349909   21.0750          NaN        0    1.0  \n",
      "8        2            347742   11.1333          NaN        0    0.0  \n",
      "9        0            237736   30.0708          NaN        1    1.0  \n",
      "10       1           PP 9549   16.7000           G6        0    1.0  \n",
      "11       0            113783   26.5500         C103        0    0.0  \n",
      "12       0         A/5. 2151    8.0500          NaN        0    0.0  \n",
      "13       5            347082   31.2750          NaN        0    0.0  \n",
      "14       0            350406    7.8542          NaN        0    1.0  \n",
      "15       0            248706   16.0000          NaN        0    0.0  \n",
      "16       1            382652   29.1250          NaN        2    1.0  \n",
      "17       0            244373   13.0000          NaN        0    NaN  \n",
      "18       0            345763   18.0000          NaN        0    0.0  \n",
      "19       0              2649    7.2250          NaN        1    NaN  \n",
      "20       0            239865   26.0000          NaN        0    0.0  \n",
      "21       0            248698   13.0000          D56        0    0.0  \n",
      "22       0            330923    8.0292          NaN        2    1.0  \n",
      "23       0            113788   35.5000           A6        0    0.0  \n",
      "24       1            349909   21.0750          NaN        0    1.0  \n",
      "25       5            347077   31.3875          NaN        0    0.0  \n",
      "26       0              2631    7.2250          NaN        1    NaN  \n",
      "27       2             19950  263.0000  C23 C25 C27        0    0.0  \n",
      "28       0            330959    7.8792          NaN        2    NaN  \n",
      "29       0            349216    7.8958          NaN        0    NaN  \n",
      "..     ...               ...       ...          ...      ...    ...  \n",
      "861      0             28134   11.5000          NaN        0    0.0  \n",
      "862      0             17466   25.9292          D17        0    0.0  \n",
      "863      2          CA. 2343   69.5500          NaN        0    NaN  \n",
      "864      0            233866   13.0000          NaN        0    0.0  \n",
      "865      0            236852   13.0000          NaN        0    0.0  \n",
      "866      0     SC/PARIS 2149   13.8583          NaN        1    0.0  \n",
      "867      0          PC 17590   50.4958          A24        0    0.0  \n",
      "868      0            345777    9.5000          NaN        0    NaN  \n",
      "869      1            347742   11.1333          NaN        0    1.0  \n",
      "870      0            349248    7.8958          NaN        0    0.0  \n",
      "871      1             11751   52.5542          D35        0    0.0  \n",
      "872      0               695    5.0000  B51 B53 B55        0    0.0  \n",
      "873      0            345765    9.0000          NaN        0    0.0  \n",
      "874      0         P/PP 3381   24.0000          NaN        1    0.0  \n",
      "875      0              2667    7.2250          NaN        1    1.0  \n",
      "876      0              7534    9.8458          NaN        0    0.0  \n",
      "877      0            349212    7.8958          NaN        0    0.0  \n",
      "878      0            349217    7.8958          NaN        0    NaN  \n",
      "879      1             11767   83.1583          C50        1    0.0  \n",
      "880      1            230433   26.0000          NaN        0    0.0  \n",
      "881      0            349257    7.8958          NaN        0    0.0  \n",
      "882      0              7552   10.5167          NaN        0    0.0  \n",
      "883      0  C.A./SOTON 34068   10.5000          NaN        0    0.0  \n",
      "884      0   SOTON/OQ 392076    7.0500          NaN        0    0.0  \n",
      "885      5            382652   29.1250          NaN        2    0.0  \n",
      "886      0            211536   13.0000          NaN        0    0.0  \n",
      "887      0            112053   30.0000          B42        0    0.0  \n",
      "888      2        W./C. 6607   23.4500          NaN        0    NaN  \n",
      "889      0            111369   30.0000         C148        1    0.0  \n",
      "890      0            370376    7.7500          NaN        2    0.0  \n",
      "\n",
      "[891 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import tree\n",
    "\n",
    "print(train)\n",
    "\n",
    "target = train[\"Survived\"].values\n",
    "features_one = train[[\"Pclass\", \"Sex\", \"Fare\"]].values\n",
    "\n",
    "my_tree_one = tree.DecisionTreeClassifier()\n",
    "my_tree_one = my_tree_one.fit(features_one, target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to quickly see the result of our decision tree is to see the importance of the features that are included. This is done by requesting the .feature_importances_ attribute of our tree object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12379776  0.41123936  0.46496288]\n"
     ]
    }
   ],
   "source": [
    "print(my_tree_one.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature_importances_ attribute made it simple to interpret the significance of the predictors we included. Based on our decision tree, the variable \"Fare\" plays the most important role in determining whether or not a passenger survived according by having the highest percentage (46.5%) of all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another quick metric is the mean accuracy that we compute using the .score() function with features_one and target as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904601571268\n"
     ]
    }
   ],
   "source": [
    "print(my_tree_one.score(features_one, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To send a submission to Kaggle we need to predict the survival rates for the observations in the test set. Before now we created simple predictions based on a single subset. Luckily, with our decision tree, we can make use of some simple functions to \"generate\" our answer without having to manually perform subsetting.\n",
    "\n",
    "First, we have to make use of the .predict() method. In the model (my_tree_one), we put the values of features from the dataset for which the predictions need to be made (test). To extract the features we will need to create a numpy array in the same way as we did when training the model. However, we need to take care of a small but important problem first. There is a missing value in the Fare feature that needs to be imputed.\n",
    "\n",
    "Next, we need to make sure that our output is in line with the submission requirements of Kaggle: a csv file with exactly 418 entries and two columns: PassengerId and Survived. Then we have to use the code provided to make a new data frame using DataFrame(), and create a csv file using to_csv() method from Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Pclass                                               Name  \\\n",
      "0            892       3                                   Kelly, Mr. James   \n",
      "1            893       3                   Wilkes, Mrs. James (Ellen Needs)   \n",
      "2            894       2                          Myles, Mr. Thomas Francis   \n",
      "3            895       3                                   Wirz, Mr. Albert   \n",
      "4            896       3       Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
      "5            897       3                         Svensson, Mr. Johan Cervin   \n",
      "6            898       3                               Connolly, Miss. Kate   \n",
      "7            899       2                       Caldwell, Mr. Albert Francis   \n",
      "8            900       3          Abrahim, Mrs. Joseph (Sophie Halaut Easu)   \n",
      "9            901       3                            Davies, Mr. John Samuel   \n",
      "10           902       3                                   Ilieff, Mr. Ylio   \n",
      "11           903       1                         Jones, Mr. Charles Cresson   \n",
      "12           904       1      Snyder, Mrs. John Pillsbury (Nelle Stevenson)   \n",
      "13           905       2                               Howard, Mr. Benjamin   \n",
      "14           906       1  Chaffee, Mrs. Herbert Fuller (Carrie Constance...   \n",
      "15           907       2      del Carlo, Mrs. Sebastiano (Argenia Genovesi)   \n",
      "16           908       2                                  Keane, Mr. Daniel   \n",
      "17           909       3                                  Assaf, Mr. Gerios   \n",
      "18           910       3                       Ilmakangas, Miss. Ida Livija   \n",
      "19           911       3              Assaf Khalil, Mrs. Mariana (Miriam\")\"   \n",
      "20           912       1                             Rothschild, Mr. Martin   \n",
      "21           913       3                          Olsen, Master. Artur Karl   \n",
      "22           914       1               Flegenheim, Mrs. Alfred (Antoinette)   \n",
      "23           915       1                    Williams, Mr. Richard Norris II   \n",
      "24           916       1    Ryerson, Mrs. Arthur Larned (Emily Maria Borie)   \n",
      "25           917       3                            Robins, Mr. Alexander A   \n",
      "26           918       1                       Ostby, Miss. Helene Ragnhild   \n",
      "27           919       3                                  Daher, Mr. Shedid   \n",
      "28           920       1                            Brady, Mr. John Bertram   \n",
      "29           921       3                                  Samaan, Mr. Elias   \n",
      "..           ...     ...                                                ...   \n",
      "388         1280       3                               Canavan, Mr. Patrick   \n",
      "389         1281       3                        Palsson, Master. Paul Folke   \n",
      "390         1282       1                         Payne, Mr. Vivian Ponsonby   \n",
      "391         1283       1     Lines, Mrs. Ernest H (Elizabeth Lindsey James)   \n",
      "392         1284       3                      Abbott, Master. Eugene Joseph   \n",
      "393         1285       2                               Gilbert, Mr. William   \n",
      "394         1286       3                           Kink-Heilmann, Mr. Anton   \n",
      "395         1287       1     Smith, Mrs. Lucien Philip (Mary Eloise Hughes)   \n",
      "396         1288       3                               Colbert, Mr. Patrick   \n",
      "397         1289       1  Frolicher-Stehli, Mrs. Maxmillian (Margaretha ...   \n",
      "398         1290       3                     Larsson-Rondberg, Mr. Edvard A   \n",
      "399         1291       3                           Conlon, Mr. Thomas Henry   \n",
      "400         1292       1                            Bonnell, Miss. Caroline   \n",
      "401         1293       2                                    Gale, Mr. Harry   \n",
      "402         1294       1                     Gibson, Miss. Dorothy Winifred   \n",
      "403         1295       1                             Carrau, Mr. Jose Pedro   \n",
      "404         1296       1                       Frauenthal, Mr. Isaac Gerald   \n",
      "405         1297       2       Nourney, Mr. Alfred (Baron von Drachstedt\")\"   \n",
      "406         1298       2                          Ware, Mr. William Jeffery   \n",
      "407         1299       1                         Widener, Mr. George Dunton   \n",
      "408         1300       3                    Riordan, Miss. Johanna Hannah\"\"   \n",
      "409         1301       3                          Peacock, Miss. Treasteall   \n",
      "410         1302       3                             Naughton, Miss. Hannah   \n",
      "411         1303       1    Minahan, Mrs. William Edward (Lillian E Thorpe)   \n",
      "412         1304       3                     Henriksson, Miss. Jenny Lovisa   \n",
      "413         1305       3                                 Spector, Mr. Woolf   \n",
      "414         1306       1                       Oliva y Ocana, Dona. Fermina   \n",
      "415         1307       3                       Saether, Mr. Simon Sivertsen   \n",
      "416         1308       3                                Ware, Mr. Frederick   \n",
      "417         1309       3                           Peter, Master. Michael J   \n",
      "\n",
      "        Sex   Age  SibSp  Parch              Ticket      Fare  \\\n",
      "0      male  34.5      0      0              330911    7.8292   \n",
      "1    female  47.0      1      0              363272    7.0000   \n",
      "2      male  62.0      0      0              240276    9.6875   \n",
      "3      male  27.0      0      0              315154    8.6625   \n",
      "4    female  22.0      1      1             3101298   12.2875   \n",
      "5      male  14.0      0      0                7538    9.2250   \n",
      "6    female  30.0      0      0              330972    7.6292   \n",
      "7      male  26.0      1      1              248738   29.0000   \n",
      "8    female  18.0      0      0                2657    7.2292   \n",
      "9      male  21.0      2      0           A/4 48871   24.1500   \n",
      "10     male   NaN      0      0              349220    7.8958   \n",
      "11     male  46.0      0      0                 694   26.0000   \n",
      "12   female  23.0      1      0               21228   82.2667   \n",
      "13     male  63.0      1      0               24065   26.0000   \n",
      "14   female  47.0      1      0         W.E.P. 5734   61.1750   \n",
      "15   female  24.0      1      0       SC/PARIS 2167   27.7208   \n",
      "16     male  35.0      0      0              233734   12.3500   \n",
      "17     male  21.0      0      0                2692    7.2250   \n",
      "18   female  27.0      1      0    STON/O2. 3101270    7.9250   \n",
      "19   female  45.0      0      0                2696    7.2250   \n",
      "20     male  55.0      1      0            PC 17603   59.4000   \n",
      "21     male   9.0      0      1             C 17368    3.1708   \n",
      "22   female   NaN      0      0            PC 17598   31.6833   \n",
      "23     male  21.0      0      1            PC 17597   61.3792   \n",
      "24   female  48.0      1      3            PC 17608  262.3750   \n",
      "25     male  50.0      1      0           A/5. 3337   14.5000   \n",
      "26   female  22.0      0      1              113509   61.9792   \n",
      "27     male  22.5      0      0                2698    7.2250   \n",
      "28     male  41.0      0      0              113054   30.5000   \n",
      "29     male   NaN      2      0                2662   21.6792   \n",
      "..      ...   ...    ...    ...                 ...       ...   \n",
      "388    male  21.0      0      0              364858    7.7500   \n",
      "389    male   6.0      3      1              349909   21.0750   \n",
      "390    male  23.0      0      0               12749   93.5000   \n",
      "391  female  51.0      0      1            PC 17592   39.4000   \n",
      "392    male  13.0      0      2           C.A. 2673   20.2500   \n",
      "393    male  47.0      0      0          C.A. 30769   10.5000   \n",
      "394    male  29.0      3      1              315153   22.0250   \n",
      "395  female  18.0      1      0               13695   60.0000   \n",
      "396    male  24.0      0      0              371109    7.2500   \n",
      "397  female  48.0      1      1               13567   79.2000   \n",
      "398    male  22.0      0      0              347065    7.7750   \n",
      "399    male  31.0      0      0               21332    7.7333   \n",
      "400  female  30.0      0      0               36928  164.8667   \n",
      "401    male  38.0      1      0               28664   21.0000   \n",
      "402  female  22.0      0      1              112378   59.4000   \n",
      "403    male  17.0      0      0              113059   47.1000   \n",
      "404    male  43.0      1      0               17765   27.7208   \n",
      "405    male  20.0      0      0       SC/PARIS 2166   13.8625   \n",
      "406    male  23.0      1      0               28666   10.5000   \n",
      "407    male  50.0      1      1              113503  211.5000   \n",
      "408  female   NaN      0      0              334915    7.7208   \n",
      "409  female   3.0      1      1  SOTON/O.Q. 3101315   13.7750   \n",
      "410  female   NaN      0      0              365237    7.7500   \n",
      "411  female  37.0      1      0               19928   90.0000   \n",
      "412  female  28.0      0      0              347086    7.7750   \n",
      "413    male   NaN      0      0           A.5. 3236    8.0500   \n",
      "414  female  39.0      0      0            PC 17758  108.9000   \n",
      "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   \n",
      "416    male   NaN      0      0              359309    8.0500   \n",
      "417    male   NaN      1      1                2668   22.3583   \n",
      "\n",
      "               Cabin Embarked  Survived  \n",
      "0                NaN        Q         0  \n",
      "1                NaN        S         1  \n",
      "2                NaN        Q         0  \n",
      "3                NaN        S         0  \n",
      "4                NaN        S         1  \n",
      "5                NaN        S         0  \n",
      "6                NaN        Q         1  \n",
      "7                NaN        S         0  \n",
      "8                NaN        C         1  \n",
      "9                NaN        S         0  \n",
      "10               NaN        S         0  \n",
      "11               NaN        S         0  \n",
      "12               B45        S         1  \n",
      "13               NaN        S         0  \n",
      "14               E31        S         1  \n",
      "15               NaN        C         1  \n",
      "16               NaN        Q         0  \n",
      "17               NaN        C         0  \n",
      "18               NaN        S         1  \n",
      "19               NaN        C         1  \n",
      "20               NaN        C         0  \n",
      "21               NaN        S         0  \n",
      "22               NaN        S         1  \n",
      "23               NaN        C         0  \n",
      "24   B57 B59 B63 B66        C         1  \n",
      "25               NaN        S         0  \n",
      "26               B36        C         1  \n",
      "27               NaN        C         0  \n",
      "28               A21        S         0  \n",
      "29               NaN        C         0  \n",
      "..               ...      ...       ...  \n",
      "388              NaN        Q         0  \n",
      "389              NaN        S         0  \n",
      "390              B24        S         0  \n",
      "391              D28        S         1  \n",
      "392              NaN        S         0  \n",
      "393              NaN        S         0  \n",
      "394              NaN        S         0  \n",
      "395              C31        S         1  \n",
      "396              NaN        Q         0  \n",
      "397              B41        C         1  \n",
      "398              NaN        S         0  \n",
      "399              NaN        Q         0  \n",
      "400               C7        S         1  \n",
      "401              NaN        S         0  \n",
      "402              NaN        C         1  \n",
      "403              NaN        S         0  \n",
      "404              D40        C         0  \n",
      "405              D38        C         0  \n",
      "406              NaN        S         0  \n",
      "407              C80        C         0  \n",
      "408              NaN        Q         1  \n",
      "409              NaN        S         1  \n",
      "410              NaN        Q         1  \n",
      "411              C78        Q         1  \n",
      "412              NaN        S         1  \n",
      "413              NaN        S         0  \n",
      "414             C105        C         1  \n",
      "415              NaN        S         0  \n",
      "416              NaN        S         0  \n",
      "417              NaN        C         0  \n",
      "\n",
      "[418 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Impute the missing value with the median\n",
    "test.Fare[152] = test.Fare.median()\n",
    "\n",
    "# Extract the features from the test set: Pclass, Sex, Age, and Fare.\n",
    "test_features = test[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].values\n",
    "\n",
    "# Make your prediction using the test set and print them.\n",
    "my_prediction = my_tree_one.predict(test_features)\n",
    "print(my_prediction)\n",
    "\n",
    "# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions\n",
    "PassengerId =np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(my_prediction, PassengerId, columns = [\"Survived\"])\n",
    "print(my_solution)\n",
    "\n",
    "# Check that your data frame has 418 entries\n",
    "print(my_solution.shape)\n",
    "\n",
    "# Write your solution to a csv file with the name my_solution.csv\n",
    "my_solution.to_csv(\"my_solution_two.csv\", index_label = [\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just created our first decision tree. We downloaded our csv file, and submitted the csv file to Kaggle. Result of our effort: we were placed very low and have to do better, let's see what is wrong and submit again the next time. When we created our first decision tree the default arguments for max_depth and min_samples_split were set to None. This means that no limit on the depth of our tree was set. That's a good thing right? Not so fast. We are likely overfitting. This means that while our model describes the training data extremely well, it doesn't generalize to new data, which is frankly the point of prediction. Just look at the Kaggle submission results for the simple model based on Gender and the complex decision tree. Which one does better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
